import visualizer.transforms.transforms
import visualizer.trainer.trainer
import visualizer.train_manager.train_model
import visualizer.architectures.unet_pruned
import visualizer.datasets.train_dataset
import visualizer.datasets.test_dataset
import visualizer.datasets.valid_dataset
import visualizer.data_loader.data_loader
import visualizer.utils.preprocessing
import visualizer.loss_function.dice_loss

INPUT_HEIGHT = 240
INPUT_WIDTH = 240
NUM_CLASSES = 4

# Data transformation configuration
TRANSFORM_CONFIGURATION = {
'0': {'transform_type': 'NormalizeImage', 'params': {'mean' :128.0, 'stddev': 128.0}}
}
configure_transforms.config = %TRANSFORM_CONFIGURATION

TrainDataset.transform = @configure_transforms()
TrainDataset.input_height = %INPUT_HEIGHT
TrainDataset.input_width = %INPUT_WIDTH
TrainDataset.root_dir = '/home/aghosh/workspace/Visualization-and-Medical-Image-Analysis/train/'
TRAIN_DATASET = @TrainDataset()

TestDataset.transform = @configure_transforms()
TestDataset.input_height = %INPUT_HEIGHT
TestDataset.input_width = %INPUT_WIDTH
TestDataset.root_dir = '/home/aghosh/workspace/Visualization-and-Medical-Image-Analysis/test/'
TEST_DATASET = @TestDataset()

ValidDataset.transform = @configure_transforms()
ValidDataset.input_height = %INPUT_HEIGHT
ValidDataset.input_width = %INPUT_WIDTH
ValidDataset.root_dir = '/home/aghosh/workspace/Visualization-and-Medical-Image-Analysis/valid/'
VALID_DATASET = @ValidDataset()

# Data loader configuration
get_train_valid_test_loader.batch_size = 64
get_train_valid_test_loader.random_seed = 39248
get_train_valid_test_loader.num_workers = 0
get_train_valid_test_loader.train_dataset = %TRAIN_DATASET
get_train_valid_test_loader.valid_dataset = %VALID_DATASET
get_train_valid_test_loader.test_dataset = %TEST_DATASET

DATA_LOADERS = @get_train_valid_test_loader()

# Architecture- UNet Pruned
Unet_pruned.num_classes = %NUM_CLASSES

# Train_manager
train_model.net = @Unet_pruned()
train_model.input_height = %INPUT_HEIGHT
train_model.input_width = %INPUT_WIDTH
train_model.data_loaders = %DATA_LOADERS

# Trainer
calculate_weight.data_loaders = %DATA_LOADERS
calculate_weight.num_classes = %NUM_CLASSES
calculate_weight.loader_idx = 0
calculate_weight.report_path = "report/"
class_weights = @calculate_weight()
torch.nn.CrossEntropyLoss.weight = %class_weights
# Trainer.segment_criterion = @torch.nn.CrossEntropyLoss
Trainer.secondary_loss = @torch.nn.CrossEntropyLoss

# focal_loss.alpha = 5
# Trainer.segment_criterion = @focal_loss

# DiceLoss.weight = %class_weights
Trainer.segment_criterion = @DiceLoss

Trainer.lr_step_size = 10
Trainer.lr = 1e-04
Trainer.patience = 15
Trainer.num_epochs = 100

Trainer.optimizer_class = @torch.optim.Adam
Trainer.weight_decay = 0.001
Trainer.input_width = %INPUT_WIDTH
Trainer.input_height = %INPUT_HEIGHT